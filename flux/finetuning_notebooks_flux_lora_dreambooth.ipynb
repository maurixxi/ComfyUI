{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maurixxi/ComfyUI/blob/master/flux/finetuning_notebooks_flux_lora_dreambooth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "ðŸ“Œ **This notebook has been updated in [jhj0517/finetuning-notebooks](https://github.com/jhj0517/finetuning-notebooks) repository!**\n",
        "\n",
        "## Version : 1.0.3\n",
        "---"
      ],
      "metadata": {
        "id": "doKhBBXIfS21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #(Optional) Check GPU\n",
        "\n",
        "#@markdown To train flux lora 24GB VRAM is recommended.\n",
        "#@markdown <br>You can check your GPU setup before start.\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "23yZvUlagEsx",
        "cellView": "form",
        "outputId": "3f852f36-b043-4dae-937b-772d3d7b5973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 29 00:17:58 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0              47W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNbSbsctxahq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title #1. Install Dependencies\n",
        "#@markdown This notebook is powered by https://github.com/ostris/ai-toolkit\n",
        "!git clone -b fix/gradient-checkpointing https://github.com/jhj0517/ai-toolkit.git\n",
        "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 2. (Optional) Mount Google Drive\n",
        "\n",
        "#@markdown It's not mandatory but it's recommended to mount to Google Drive and use the Google Drive's path for your training image dataset.\n",
        "\n",
        "#@markdown The dataset should have following structure:\n",
        "\n",
        "#@markdown Each image file should have a corresponding text file (`.txt`) with the same name.\n",
        "#@markdown The text file contains prompts associated with the image.\n",
        "\n",
        "#@markdown ### Example File Structure:\n",
        "#@markdown ```\n",
        "#@markdown your-dataset/\n",
        "#@markdown â”œâ”€â”€ a (1).png         # Image file\n",
        "#@markdown â”œâ”€â”€ a (1).txt         # Corresponding prompt for a (1).png\n",
        "#@markdown â”œâ”€â”€ a (2).png         # Another image file\n",
        "#@markdown â”œâ”€â”€ a (2).txt         # Corresponding prompt for a (2).png\n",
        "#@markdown ```\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M1bu3MpsACOu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 3. (Optional) Register Huggingface Token To Download Base Model\n",
        "\n",
        "#@markdown If you don't have entire base model files ([black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)) in the drive you need to sign in to Huggingface to download the model.\n",
        "\n",
        "#@markdown Get your tokens from https://huggingface.co/settings/tokens, and register it in colab's seceret as **`HF_TOKEN`** and use it in any notebook. ( 'Read' permission is enough )\n",
        "\n",
        "#@markdown To register secrets in colab, click on the key-shaped icon in the left panel and enter your **`HF_TOKEN`** like this:\n",
        "\n",
        "#@markdown ![image](https://media.githubusercontent.com/media/jhj0517/finetuning-notebooks/master/docs/screenshots/colab_secrets.png)\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9WzQRwZij5jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # 4. Train with Parameters\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "import os\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
        "\n",
        "#@markdown ## Paths Configuration\n",
        "\n",
        "#@markdown Set your dataset path and output path for lora here.\n",
        "DATASET_DIR = \"/content/drive/MyDrive/finetuning-notebooks/dataset/dog\" # @param {type:\"string\"}\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/finetuning-notebooks/flux/outputs'  # @param {type:\"string\"}\n",
        "LORA_NAME = 'Your-Lora-v1'  # @param {type:\"string\"}\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "#@markdown ## Base Model Configuration\n",
        "#@markdown If you'll just use the default repo id here then you need to register huggingface token in the previous section\n",
        "repo_id_or_path = 'black-forest-labs/FLUX.1-dev' # @param {type:\"string\"}\n",
        "quantize = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ## Process Settings\n",
        "#@markdown (max_step_saves_to_keep = how many checkpoints to keep during training. )\n",
        "dtype = \"float16\" # @param {type:\"string\"}\n",
        "save_every = 250 # @param {type:\"number\"}\n",
        "max_step_saves_to_keep = 4 # @param {type:\"number\"}\n",
        "#@markdown Whenever `sample_every` step, it will make samples to the output directory with prompts below to benchmark your result.\n",
        "#@markdown <br>Below is the example with the trigger word \"A teddy dog\". The \"trigger word\" thing is not necessary.\n",
        "sample_every = 250 # @param {type:\"number\"}\n",
        "sample_seed = 77 # @param {type: \"number\"}\n",
        "sample_steps = 20 # @param {type: \"number\"}\n",
        "sample_prompt_1 = \"A teddy dog is looking above in bedroom\" # @param {type: \"string\"}\n",
        "sample_prompt_2 = \"A teddy dog is playing with balls on the grass in sunny day\" # @param {type: \"string\"}\n",
        "sample_prompt_3 = \"A teddy dog is sleeping on the caution, the room is dark without light at night\" # @param {type: \"string\"}\n",
        "### Add `sample_prompts` as much as you need  ###\n",
        "sample_prompts = [sample_prompt_1, sample_prompt_2, sample_prompt_3]\n",
        "\n",
        "performance_log_every = 1000 # @param {type:\"number\"}\n",
        "#@markdown ### Network\n",
        "#@markdown You can train only specific layers, `only_if_contains` is enabled when `train_only_specific_layers` is True..\n",
        "linear = 16 # @param {type:\"number\"}\n",
        "linear_alpha = 16 # @param {type:\"number\"}\n",
        "## network_kwargs\n",
        "train_only_specific_layers = False # @param {type:\"boolean\"}\n",
        "only_if_contains = [\"transformer.single_transformer_blocks.7.proj_out\", \"transformer.single_transformer_blocks.20.proj_out\"] # @param {type: \"raw\"}\n",
        "\n",
        "#@markdown ## Dataset Settings\n",
        "caption_ext = \"txt\" # @param {type:\"string\"}\n",
        "caption_dropout_rate = 0.05 # @param {type:\"number\"}\n",
        "shuffle_tokens = False # @param {type:\"boolean\"}\n",
        "cache_latents_to_disk = True # @param {type:\"boolean\"}\n",
        "resolution = \"512, 768, 1024\" # @param {type:\"string\"}\n",
        "resolution = [int(res.strip()) for res in resolution.split(\",\")]\n",
        "\n",
        "#@markdown ## Training Settings\n",
        "batch_size = 1 # @param {type:\"number\"}\n",
        "# Recommended range is 500 ~ 4000\n",
        "steps = 4000 # @param {type:\"number\"}\n",
        "gradient_accumulation_steps = 1 # @param {type:\"number\"}\n",
        "train_dtype = \"bf16\" # @param {type:\"string\"}\n",
        "lr = 4e-4 # @param {type:\"number\"}\n",
        "train_unet = True # @param {type:\"boolean\"}\n",
        "train_text_encoder = False # @param {type:\"boolean\"}\n",
        "content_or_style = 'balanced' # @param [\"content\", \"style\", \"balanced\"]\n",
        "gradient_checkpointing = True # @param {type:\"boolean\"}\n",
        "noise_scheduler = 'flowmatch' # @param {type:\"string\"}\n",
        "optimizer = 'adamw8bit' # @param {type:\"string\"}\n",
        "# ema settings\n",
        "use_ema = True # @param {type:\"boolean\"}\n",
        "ema_decay = 0.99 # @param {type:\"number\"}\n",
        "\n",
        "# Training\n",
        "job_to_run = OrderedDict([\n",
        "    ('job', 'extension'),\n",
        "    ('config', OrderedDict([\n",
        "        # this name will be the folder and filename name\n",
        "        ('name', LORA_NAME),\n",
        "        ('process', [\n",
        "            OrderedDict([\n",
        "                ('type', 'sd_trainer'),\n",
        "                ('training_folder', OUTPUT_DIR),\n",
        "                ('performance_log_every', 1000),\n",
        "                ('device', 'cuda:0'),\n",
        "                ('network', OrderedDict([\n",
        "                    ('type', 'lora'),\n",
        "                    ('linear', linear),\n",
        "                    ('linear_alpha', linear_alpha)\n",
        "                ])),\n",
        "                ('save', OrderedDict([\n",
        "                    ('dtype', dtype),\n",
        "                    ('save_every', save_every),\n",
        "                    ('max_step_saves_to_keep', max_step_saves_to_keep)\n",
        "                ])),\n",
        "                ('datasets', [\n",
        "                    OrderedDict([\n",
        "                        ('folder_path', DATASET_DIR),\n",
        "                        ('caption_ext', caption_ext),\n",
        "                        ('caption_dropout_rate', caption_dropout_rate),\n",
        "                        ('shuffle_tokens', shuffle_tokens),\n",
        "                        ('cache_latents_to_disk', cache_latents_to_disk),\n",
        "                        ('resolution', resolution)\n",
        "                    ])\n",
        "                ]),\n",
        "                ('train', OrderedDict([\n",
        "                    ('batch_size', batch_size),\n",
        "                    ('steps', steps),\n",
        "                    ('gradient_accumulation_steps', gradient_accumulation_steps),\n",
        "                    ('train_unet', train_unet),\n",
        "                    ('train_text_encoder', train_text_encoder),\n",
        "                    ('content_or_style', content_or_style),\n",
        "                    ('gradient_checkpointing', gradient_checkpointing),\n",
        "                    ('noise_scheduler', noise_scheduler),\n",
        "                    ('optimizer', optimizer),\n",
        "                    ('lr', lr),\n",
        "                    ('ema_config', OrderedDict([\n",
        "                        ('use_ema', use_ema),\n",
        "                        ('ema_decay', ema_decay)\n",
        "                    ])),\n",
        "                    ('dtype', train_dtype)\n",
        "                ])),\n",
        "                ('model', OrderedDict([\n",
        "                    ('name_or_path', repo_id_or_path),\n",
        "                    ('is_flux', True),\n",
        "                    ('quantize', quantize),\n",
        "                ])),\n",
        "                ('sample', OrderedDict([\n",
        "                    ('sampler', 'flowmatch'),\n",
        "                    ('sample_every', sample_every),\n",
        "                    ('width', 1024),\n",
        "                    ('height', 1024),\n",
        "                    ('prompts', sample_prompts),\n",
        "                    ('neg', ''),\n",
        "                    ('seed', sample_seed),\n",
        "                    ('walk_seed', True),\n",
        "                    ('guidance_scale', 4),\n",
        "                    ('sample_steps', sample_steps)\n",
        "                ]))\n",
        "            ])\n",
        "        ])\n",
        "    ])),\n",
        "    ('meta', OrderedDict([\n",
        "        ('name', '[name]'),\n",
        "        ('version', '1.0')\n",
        "    ]))\n",
        "])\n",
        "\n",
        "# Conditional Parameters\n",
        "if train_only_specific_layers:\n",
        "    network = job_to_run[\"config\"][\"process\"][0][\"network\"]\n",
        "    network_kwargs = network.setdefault(\"network_kwargs\", OrderedDict())\n",
        "    network_kwargs[\"only_if_contains\"] = only_if_contains\n",
        "\n",
        "run_job(job_to_run)\n"
      ],
      "metadata": {
        "id": "fob2cRMQeW5C",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}